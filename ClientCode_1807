import os

import torch
import torch.nn as nn
import torch.optim as optim
from numpy.f2py.crackfortran import verbose
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms
import timm
import flwr as fl
import numpy as np
import gc
import random

# Data Transforms
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.2),
    transforms.RandomRotation(degrees=15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.01),
    transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),
    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=0),

    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

])

transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    # transforms.Normalize(mean=[0.362, 0.2221, 0.212], std=[0.257, 0.165, 0.096])
])


def load_model():
    model = timm.create_model('cait_xxs24_224', pretrained=True, drop_rate=0.1, attn_drop_rate=0.1)
    num_classes = 2

    # Modify the head
    if hasattr(model, 'head'):
        model.head = nn.Linear(model.head.in_features, num_classes)
    else:
        model.reset_classifier(num_classes)

    return model


def train(model, train_loader, epochs, device):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)

    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, min_lr=1e-6)
    model.to(device)
    model.train()

    for epoch in range(epochs):
        running_loss, correct, total = 0.0, 0, 0

        for i, (inputs, labels) in enumerate(train_loader):
            optimizer.zero_grad()
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()

            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()  # Update weights AFTER clipping

            running_loss += loss.item() * inputs.size(0)
            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = correct / total
        print(f"Epoch {epoch + 1}: Loss {epoch_loss:.4f}, Acc {epoch_acc:.4f}")

        scheduler.step(epoch_acc)

        # Memory cleanup
        del inputs, labels, outputs, loss, predicted
        torch.cuda.empty_cache()
        gc.collect()

    return epoch_loss, epoch_acc


def test(model, test_loader, device):
    criterion = nn.CrossEntropyLoss()
    model.to(device)
    model.eval()
    loss, correct, total = 0.0, 0, 0

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            loss += criterion(outputs, labels).item() * inputs.size(0)
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)

            del inputs, labels, outputs, predicted
            torch.cuda.empty_cache()
            gc.collect()

    return loss / len(test_loader.dataset), correct / total


class CaiTClient(fl.client.NumPyClient):
    def __init__(self, train_dataset, val_dataset, client_id, local_epochs=3):
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

        if torch.cuda.is_available():
            torch.cuda.set_per_process_memory_fraction(0.4, device=0)

        self.model = load_model().to(self.device)
        self.client_id = client_id
        self.local_epochs = local_epochs

        self.train_dataset = train_dataset
        self.val_dataset = val_dataset

        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=16,
            shuffle=True,
            num_workers=os.cpu_count() // 2 if os.cpu_count() else 1,
            pin_memory=True if torch.cuda.is_available() else False
        )

        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=16,
            shuffle=False,
            num_workers=os.cpu_count() // 2 if os.cpu_count() else 1,
            pin_memory=True if torch.cuda.is_available() else False
        )

    def get_parameters(self, config):
        return [val.cpu().numpy() for val in self.model.state_dict().values()]

    def set_parameters(self, parameters):
        params_dict = zip(self.model.state_dict().keys(), parameters)
        state_dict = {k: torch.tensor(v).to(self.device) for k, v in params_dict}
        self.model.load_state_dict(state_dict, strict=True)

    def fit(self, parameters, config):
        self.set_parameters(parameters)
        loss, accuracy = train(self.model, self.train_loader, self.local_epochs, self.device)

        # Return metrics along with parameters
        metrics = {
            "train_loss": float(loss),
            "train_accuracy": float(accuracy),
            "client_id": self.client_id
        }

        return self.get_parameters(config={}), len(self.train_loader.dataset), metrics

    def evaluate(self, parameters, config):
        self.set_parameters(parameters)
        loss, accuracy = test(self.model, self.val_loader, self.device)
        return float(loss), len(self.val_loader.dataset), {"accuracy": float(accuracy)}


def main():
    # Load full datasets
    train_dataset_full = datasets.ImageFolder(
        r"C:\Users\Gaming PC\Documents\Aptos Dataset\Aptos_Binary_Class_Enhanced\Train_Splits\split_2\Train",
        transform=transform_train)
    val_dataset_full = datasets.ImageFolder(
        r"C:\Users\Gaming PC\Documents\Aptos Dataset\Aptos_Binary_Class_Enhanced\Train_Splits\split_2\Val",
        transform=transform_val)
    # Client configuration (run with different client_id for each client)
    client_id = 2
    # num_clients = 2

    # Initialize client
    client = CaiTClient(
        train_dataset_full,
        val_dataset_full,
        client_id=client_id,
        local_epochs=3,
    )

    # Start Flower client
    fl.client.start_numpy_client(server_address="localhost:8082", client=client)


if __name__ == "__main__":
    main()
